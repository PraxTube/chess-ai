The development of a chess AI presents a multitude of challenges, making it a fertile ground for learning. Failure is often the first step towards mastery, and this project was no exception. The following list encapsulates the key lessons we gleaned from this project, presented in no particular order:

\begin{itemize}
\item Benchmarks are invaluable, not only for tracking improvements across different code versions but also for comparing the impact of incremental changes. This became evident during our attempt to refactor the evaluation function using numpy.
\item Effective team coordination is crucial, especially when working on complex projects like a chess AI. Clear communication and division of tasks can help prevent misunderstandings and ensure that everyone is on the same page.
\item Resolving merge conflicts on GitHub can be challenging, but it's an essential skill for collaborative software development. It's important to understand the changes made by each team member and ensure that important updates are not accidentally discarded.
\item It's important to be flexible and adaptable in your approach. If a particular method or tool isn't working as expected, don't be afraid to try something different.
\item Research is a critical part of the development process. Understanding the underlying principles and algorithms can help you make more informed decisions and avoid potential pitfalls.
\item Regularly reviewing and refactoring your code can lead to improvements in both performance and readability. It can also make it easier to add new features or make changes in the future.
\item It's important to balance the pursuit of optimal performance with the practical limitations of your chosen programming language and tools. Sometimes, the most efficient solution may not be the most practical one.
\item Implementing advanced features and algorithms can significantly improve the performance of your AI, but it's important to understand these features thoroughly to avoid introducing new issues or inefficiencies.
\item The influence of background tasks on benchmark results should not be underestimated. Consistency in the testing environment is crucial for obtaining reliable results.
\item Developing debugging and logging tools early in the project can significantly streamline the development process.
\item Adopting a 'fail fast' approach in the project's early stages, such as using python-chess to create a simple AI, can provide a solid foundation for future development.
\item Writing clear and concise git commits is crucial for both documentation and workflow. Atomic commits are particularly beneficial when restructuring complex software like the chess backend.
\item Unit tests are invaluable when restructuring complex software.
\item Before committing to a task that requires significant time and effort, it's important to assess whether the potential benefits justify the investment. Our attempt to implement transposition tables served as a lesson in this regard.
\item Debugging hash tables can be more complex than it initially appears. Proficiency in using a debugger is a vital skill for software developers.
\item Creating a chess AI is a more demanding task than it may initially seem. It involves not only writing the chess backend and ensuring the AI functions as intended, but also debugging both the AI and the backend, and regularly benchmarking to ensure progress is on track. This observation likely extends to the creation of AI in general, even without venturing into the realm of machine learning.
\end{itemize}

These points reflect the diverse range of technical and project management lessons we learned during the development of the chess AI.
